## This code can update separate ticker files, or combined files, generated by single_download.py or prelim_download.py
## Author: Miguel Ope√±a
## Version: 3.2.1

import datetime
import pandas as pd
import time
import sys
import glob

import single_download
import prelim_download
import ticker_universe

# Delay prevents HTTP 503 errors (AlphaVantage recommends 10, but 15 works in practice)
DELAY = 11

def update_combined(folderPath, filePath, apiKey, dataType="csv"):
	""" Automatically updates the COMBINED file at the given path. The name of said file must follow naming conventions within this program!

		Inputs: folder path to look for files, file path of actual file, API key of user, data type (default: CSV)
		Outputs: the new combined dataFrame
	"""
	# Reads the old data from its file location
	oldData = pd.read_csv(filePath, index_col='timestamp')
	oldData.dropna(how='all',inplace=True)
	# Gets the most recent date in the old ticker data
	lastDate = oldData.index[-1]
	fileName = filePath.split(folderPath)[1][1:]
	nameSplit = fileName.split("." + dataType)[0].split("_")
	universe = tickerNameSplit[0]
	print("Auto-updating " + universe + " ticker universe from AlphaVantage...")
	universeList = []
	if universe == "SNP500" or universe == "DOW30": 
		seed="^GSPC" if universe == "SNP500" else "^DJI"
		universeList = ticker_universe.obtain_parse_wiki(selection=universe, seed=seed)
	elif universe == "NASDAQ100":
		universeList = ticker_universe.obtain_parse_nasdaq()
	# Gets the function (daily, intradaily, etc.) from the file name
	function = tickerNameSplit[2]
	interval = ""
	if "&" in function:
		function = function.split("&")[0]
		interval = function.split("&")[1]
	# We only need the compact version if the data is not intraday
	outputSize = "compact"
	if function == "INTRADAY":
		outputSize = "full"
	newData = prelim_download.download_combined(universeList, apiKey, function=function, outputSize=outputSize, writeFile=False, interval=interval)
	# Isolates the data that is new (based on last date/time collected)
	newData = newData[(newData.index == lastDate).cumsum() == 0]
	allData = pd.concat([oldData, newData])
	print("Data on " + universe + " successfully updated!\n")
	return 0

def update_separate(folderPath, filePath, apiKey, dataType="csv"):
	""" Automatically updates the SEPARATE file at the given path. The name of said file must follow naming conventions within this program!

		Inputs: folder path to look for files, file path of actual file, API key of user, data type (default: CSV)
		Outputs: 0 if everything works
	"""
	# Reads the old data from its file location
	oldData = pd.read_csv(filePath, index_col='timestamp')
	oldData.dropna(how='any',inplace=True)
	# Gets the most recent date in the old ticker data
	lastDate = oldData.index[-1]
	# Parses the file name using the split function
	fileName = filePath.split(folderPath)[1][1:]
	tickerNameSplit = fileName.split("." + dataType)[0].split("_")		
	symbol = tickerNameSplit[0]
	print("Auto-updating " + symbol + " from AlphaVantage...")
	# Gets the function (daily, intradaily, etc.) from the file name
	function = tickerNameSplit[1]
	interval = ""
	if "&" in function:
		function = function.split("&")[0]
		interval = function.split("&")[1]
	# We only need the compact version if the data is not intraday
	outputSize = "compact"
	if function == "INTRADAY":
		outputSize = "full"
	newData = single_download.fetch_symbol(symbol, apiKey, function=function, outputSize=outputSize, dataType=dataType, interval=interval)
	# Isolates the data that is new (based on last date/time collected)
	newData = newData[(newData.index == lastDate).cumsum() == 0]
	allData = pd.concat([oldData, newData])
	# Writes allTickerData to chosen folder path
	allData.to_csv(filePath, index_label='timestamp')
	print("Data on " + symbol + " successfully updated!\n")
	# Delay prevents HTTP 503 errors
	time.sleep(DELAY)
	# Returns 0 if the program runs to completion
	return 0

def main():
	""" User interacts with interface through command prompt, which obtains several "input" data. 
		Here is an example of how to run this program: 

		python auto_update.py -folderPath C:/Users/Miguel/Desktop/stockData -apiKey <INSERT KEY>
			This will download separate files of daily data on S&P 500 tickers to the desired folder path.

		Inputs: implicit through command prompt
		Outputs: 0 if everything works
	"""
	prompts = sys.argv
	## Default datatype is CSV. User cannot change this. 
	dataType = "csv"
	## Handles where the user wants to download their files. 
	# Default folder path is relevant to the author only. 
	folderPath = "C:/Users/Miguel/Documents/stockData"
	if "-folderPath" not in prompts:
		print("Warning: the program will use default file paths, which may not be compatible on your computer.")
	else: 
		folderPath = prompts[prompts.index("-folderPath") + 1]
	## Handles the user's API key. 
	apiKey = ""
	if "-apiKey" in prompts:
		apiKey = prompts[prompts.index("-apiKey") + 1]
	else:
		raise ValueError("No API key provided. Please try again.")
	## Gets all files of dataType in the folder
	allFiles = glob.glob(folderPath + "/*." + dataType)
	## Updates separate and combined files, depending on file name
	for filePath in allFiles:
		if "COMBINED" in filePath:
			update_combined(folderPath, filePath, apiKey, dataType=dataType)
		else:
			update_separate(folderPath, filePath, apiKey, dataType=dataType)

if __name__ == "__main__":
	main()
