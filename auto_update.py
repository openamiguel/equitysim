## This code can update separate ticker files, or combined files, generated by single_download.py or prelim_download.py
## Author: Miguel OpeÃ±a
## Version: 4.0.0

import datetime
import pandas as pd
import time
import sys
import glob

import command_parser
import download
import ticker_universe

# Delay prevents HTTP 503 errors (AlphaVantage recommends 10, but 15 works in practice)
DELAY = 15

def update_in_folder(folderPath, filePath, apiKey):
	""" Automatically updates the SEPARATE file at the given path. The name of said file must follow naming conventions within this program!

		Inputs: folder path to look for files, file path of actual file, API key of user
		Outputs: 0 if everything works
	"""
	# Reads the old data from its file location
	oldData = pd.read_csv(filePath, index_col='timestamp')
	oldData.dropna(how='any',inplace=True)
	# Removes duplicates
	oldData = oldData[~oldData.index.duplicated(keep='first')]
	# Gets the most recent date in the old ticker data
	lastDate = oldData.index[-1]
	# Parses the file name using the split function
	fileName = filePath.split(folderPath)[1][1:]
	nameSplit = fileName.split("." + dataType)[0].split("_")		
	symbol = nameSplit[0]
	print("Auto-updating " + symbol + " from AlphaVantage...")
	# Gets the function (daily, intradaily, etc.) from the file name
	# Now gets the adjusted ones properly
	function = "_".join(nameSplit[1:])
	interval = ""
	if "&" in function:
		functionSplit = function.split("&")
		function = functionSplit[0]
		interval = functionSplit[1]
	# We only need the compact version if the data is not intraday
	outputSize = "compact"
	if function == "INTRADAY":
		outputSize = "full"
	newData = single_download.fetch_symbol(symbol, apiKey, function=function, outputSize=outputSize, interval=interval)
	# If unavailable, don't download
	if newData is None:
		# Delay prevents HTTP 503 errors
		print(symbol + " update failed and skipped.\n")
		time.sleep(DELAY)
		return None
	# Isolates the data that is new (based on last date/time collected)
	newData = newData[(newData.index == lastDate).cumsum() > 0]
	if lastDate in newData.index:
		newData.drop(index=lastDate, inplace=True)
	allData = pd.concat([oldData, newData])
	# Writes allTickerData to chosen folder path
	allData.to_csv(filePath, index_label='timestamp')
	print("Data on " + symbol + " successfully updated!\n")
	# Delay prevents HTTP 503 errors
	time.sleep(DELAY)
	# Returns 0 if the program runs to completion
	return 0

def main():
	""" User interacts with interface through command prompt, which obtains several "input" data. 
		Here is an example of how to run this program: 

		python auto_update.py -folderPath C:/Users/Miguel/Desktop/stockData -apiKey <INSERT KEY>
			This will download separate files of daily data on S&P 500 tickers to the desired folder path.

		Inputs: implicit through command prompt
		Outputs: 0 if everything works
	"""
	prompts = sys.argv
	## Handles where the user wants to download their files. 
	# Default folder path is relevant to the author only. 
	folderPath = command_parser.get_generic_from_prompts(prompts, query="-folderPath", default="C:/Users/Miguel/Documents/stockData", req=False)
	## Handles the user's API key. 
	apiKey = command_parser.get_generic_from_prompts(prompts, query="-apiKey")
	## Gets all files of dataType in the folder
	allFiles = glob.glob(folderPath + "/*." + dataType)
	## Updates all files in folder
	for filePath in allFiles:
		update_in_folder(folderPath, filePath, apiKey)

if __name__ == "__main__":
	main()